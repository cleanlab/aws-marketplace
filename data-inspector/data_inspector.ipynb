{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Identify Errors in Your Dataset with Data Inspector from AWS Marketplace \n",
    "\n",
    "\n",
    "Cleanlab's [Data Inspector](TODO: link) automatically detects errors in your tabular datasets. \n",
    "\n",
    "This sample notebook demonstrates how to use the Data Inspector via Amazon SageMaker. You can either run it locally from your computer, or from within Sagemaker (recommended).\n",
    "\n",
    "View our handy [AWS Marketplace Guide](../GUIDE.md) if you get stuck anywhere, especially with providing credentials/ARNs or other setup steps.\n",
    "\n",
    "## Pre-requisites\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to [Data Inspector](TODO: link). \n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to Label Inspector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the Label Inspector offering:\n",
    "1. Open the AWS Marketplace listing page for [Data Inspector](TODO: link).\n",
    "1. On the listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with the EULA and pricing terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify to use this algorithm. Copy the ARN corresponding to your region and specify it in the following cell.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you enter the algorithm ARN in the call below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo_arn = \"<Specify the ARN for Data Inspector obtained from AWS Marketplace>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two code cells below might have a different setup if you are running this sample notebook locally, please check out the [guide to run sample notebooks locally](../GUIDE.md/#run-sample-notebooks-locally) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session = boto3.Session()\n",
    "    sagemaker_session = sage.Session(session)\n",
    "\n",
    "except ValueError:\n",
    "    # AWS access key id and secret access key only needs to be specified if running notebook locally \n",
    "    # (and AWS credentials were not previously setup)\n",
    "    aws_access_key_id = \"<Specify your AWS Access ID>\"\n",
    "    aws_secret_access_key = \"<Specify your AWS Secret Access Key>\"\n",
    "    region = \"us-east-1\"  # replace with other region if you want, ensure that it matches the region in the ARN\n",
    "    session = boto3.Session(aws_access_key_id, aws_secret_access_key, region_name=region)\n",
    "    sagemaker_session = sage.Session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local variable only needs to be specified if running notebook locally rather than in Sagemaker\n",
    "local_variable_for_sm_role = \"arn:aws:iam::XXXXXX:role/service-role/SageMaker-XXXXX\"  \n",
    "\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except ValueError:\n",
    "    role = local_variable_for_sm_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define S3 locations for saving data, replace if you would like to store your data in alternative locations\n",
    "bucket_name = sagemaker_session.default_bucket()  # bucket where data will be stored\n",
    "base_folder_name = \"data-inspector\"  # folder inside your bucket where data will be stored\n",
    "\n",
    "training_instance_type = \"ml.m5.xlarge\"  # what type of EC2 instance to use (i.e. how powerful of a computer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of EC2 instance will affect how much data can be handled (due to memory limits), how long it takes to return results (ML training takes time), and possibly how accurate the results are. More powerful instances will improve things along all these dimensions.\n",
    "\n",
    "If your dataset contains text fields (strings that are not discrete categories), we recommend a p*-instance that has GPU such that large language models can be fine-tuned on your data. Use of GPU will produce more accurate results for datasets with text.\n",
    "\n",
    "If your dataset is big (over 100k rows), we recommend an instance with lots of memory: \"ml.m5.24xlarge\" if there are no text fields, \"ml.p3.16xlarge\" otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Prepare dataset and Upload to Amazon S3 (skip if data is already in S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Sample Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example dataset that you can run Data Inspector on. Data inspector will take approximately 10 minutes to train various ML model and identify any potential errors in this sample dataset.\n",
    "\n",
    "If using your own data, please ensure that the first line of your CSV file is a header with the column names for your data. Your data can optionally contain a unique index or ID column, which can be specified to Data Inspector later on (eg. `stud_ID` is the unique ID column for this sample dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stud_ID</th>\n",
       "      <th>name</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>letter_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f48f73</td>\n",
       "      <td>Nicole Carter</td>\n",
       "      <td>53</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0bd4e7</td>\n",
       "      <td>Tammy Myers</td>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>great participation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e1795d</td>\n",
       "      <td>Lillian Lucas</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb9d7a</td>\n",
       "      <td>Danielle Graham</td>\n",
       "      <td>61</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9acca4</td>\n",
       "      <td>Wilbur Fleming</td>\n",
       "      <td>48</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stud_ID             name  exam_1  exam_2  exam_3                    notes  \\\n",
       "0  f48f73    Nicole Carter      53      77      93                      NaN   \n",
       "1  0bd4e7      Tammy Myers      81      64      80  great participation +10   \n",
       "2  e1795d    Lillian Lucas      74      88      97                      NaN   \n",
       "3  cb9d7a  Danielle Graham      61      94      78                      NaN   \n",
       "4  9acca4   Wilbur Fleming      48      90      91                      NaN   \n",
       "\n",
       "  letter_grade  \n",
       "0            C  \n",
       "1            B  \n",
       "2            B  \n",
       "3            C  \n",
       "4            C  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/input/dataset.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset = \"data/input/dataset.csv\"  # replace filepath here if using your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload data to S3\n",
    "input_folder = \"{}/{}/{}\".format(base_folder_name, \"train\", \"input\")\n",
    "training_data_location = sagemaker_session.upload_data(training_dataset, bucket=bucket_name, key_prefix=input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find your data here after uploading\n",
    "training_data_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a ML model to analyze the labels in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After ensuring that our data is an accessible Amazon S3 bucket (only read permissions are required for the algorithm to access the input data bucket), we are ready to train a machine learning model. This model can be automatically trained on diverse types of tabular/text data via state-of-the-art AutoML, and is used to identify which labels are likely incorrect. \n",
    "\n",
    "In the code cell below we specify the S3 location of our data. If you have followed the [Upload datasets to Amazon S3](#Upload-datasets-to-Amazon-S3) section of this tutorial, the S3 location should already be specified. If you are using your own dataset, make sure to specify the location of your data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data_location  # replace with the S3 URI of your data if using your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the output folder location based on variables specified above\n",
    "# this is boilerplate code and does not need to be edited\n",
    "output_location = \"s3://{}/{}/{}/{}\".format(bucket_name, base_folder_name, \"train\", \"output\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify the hyperparameters for our algorithm. Data Inspector supports 3 hyperparameters:\n",
    "\n",
    "- The `runtime` argument specifies the training mode, there are two options:\n",
    "    1. `fast` will have a shorter execution time, but may not produce the best quality results (maximum execution time: 3 hours, will take much less time for most datasets)\n",
    "    2. `high_accuracy` will be slower, but produces high quality results (maximum execution time: 15 hours, will take much less time for most datasets)\n",
    "\n",
    "    In either case, you can get results faster by specifying a more powerful `instance_type` (and the results may be more accurate). When estimating costs, keep in mind that a more powerful instance can run the job faster (and has more memory available which may be required for larger datasets). ML training scales proportionally to the size of your dataset and may take some time, so just keep this job running and check back later to see if it has completed.\n",
    "    \n",
    "- The `index_col` argument specifies the column to use as the index of the dataset. This index column name should be passed in as a string (eg. `\"stud_ID\"`).\n",
    "\n",
    "- The `columns_to_inspect` argument specifies the columns that should be checked for data issues. This should be a list of column names in your dataset (eg. `[\"letter_grade\", \"exam_1\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"runtime\": \"high_accuracy\",  # change to \"fast\" to get quicker results (will be less accurate)\n",
    "    \"index_col\": \"stud_ID\",  # specify\n",
    "    # \"columns_to_inspect\": [\"letter_grade\", \"exam_1\"]  # can specify a subset of columns to inspect\n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create an estimator object for running a training job and train our model. For information on creating an `Estimator` object, check out the [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"data-inspector\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: data-inspector-2023-05-12-04-25-05-478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-12 04:25:05 Starting - Starting the training job...\n",
      "2023-05-12 04:25:19 Starting - Preparing the instances for training...\n",
      "2023-05-12 04:26:10 Downloading - Downloading input data...\n",
      "2023-05-12 04:26:30 Training - Downloading the training image.....................\n",
      "2023-05-12 04:30:06 Training - Training image download completed. Training in progress..\n",
      "\u001b[34mAnalyzing your data ... the estimated maximum runtime (upper bound) is: 15 hours\u001b[0m\n",
      "\u001b[34mColumns ['name'] were not inspected.\u001b[0m\n",
      "\n",
      "2023-05-12 04:36:49 Uploading - Uploading generated training model\n",
      "2023-05-12 04:36:49 Completed - Training job completed\n",
      "Training seconds: 638\n",
      "Billable seconds: 638\n"
     ]
    }
   ],
   "source": [
    "# run the training job\n",
    "estimator.fit({\"training\": training_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your output will be available on following path\n",
    "output_file_location = os.path.join(output_location, estimator._current_job_name, \"output\")\n",
    "output_file_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Model Training Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get results faster (but potentially less accurate estimates): Specify a more powerful instance type and set `hyperparameters = {\"runtime\": \"fast\"}`. You can also try subsampling your dataset to a smaller one for a quick trial run (although be aware the ML training -- and hence accuracy of estimated label issues -- will become worse when the dataset is small). \n",
    "\n",
    "To get more accurate results: Specify a more powerful instance type. If you have text fields in your datasetÂ (i.e. strings that are not discrete categories), use an instance that has a GPU (like a p-instance or g-instance) so large language models can be fine-tuned on your data. Also set `hyperparameters = {\"runtime\": \"high_accuracy\"}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fetch results of the data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training job completes, we can get the results output by this analysis from the S3 bucket specified above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = session.client('s3')\n",
    "\n",
    "# create local folder to store output files\n",
    "if not os.path.exists('data/output'):\n",
    "    os.makedirs('data/output')\n",
    "\n",
    "# downloading the file from S3\n",
    "with open('data/output/output.tar.gz', 'wb') as f:\n",
    "    s3.download_fileobj(bucket_name, f\"{base_folder_name}/train/output/{estimator._current_job_name}/output/output.tar.gz\", f)\n",
    "    \n",
    "# extracting the downloaded tar.gz file to a outpuit folder\n",
    "with tarfile.open('data/output/output.tar.gz') as file:\n",
    "    file.extractall('data/output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Inspector outputs 3 CSV files containing information about each datapoint in your dataset:\n",
    "\n",
    "- `is_issue.csv` contains boolean True/False values specifying whether each datapoint is inferred to be an error\n",
    "- `quality_score.csv` contains quality scores between 0 and 1 estimating the likelihood that each datapoint is an error (lower scores indicate noiser data)\n",
    "- `imputed_values.csv` contains a model predicted value for each datapoint\n",
    "\n",
    "All 3 CSV files that are returned will contain the same number of rows as your original dataset, and the columns which you have specified in `columns_to_inspect`. If `columns_to_inspect` was not specified, then they will contains all the columns in your original dataset. Each error boolean value, quality score and imputed value will correspond to the data at each row and column of your input dataset. \n",
    "\n",
    "The datapoints flagged as likely mislabeled with the lowest label quality scores are the ones whose labels you should review closely. \n",
    "\n",
    "Note that columns that were skipped during the inspection will always have `is_issue = False` and `quality_score = 1` for all rows. For example, in this sample dataset the `name` column contains unique string names, which does not make sense to be inspected, hence there will be no results for that column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load all the results alongside our input data. We can also view an example of some of the return files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_dataset = pd.read_csv(\"data/input/dataset.csv\", index_col=\"stud_ID\") # replace filepath here if using your own dataset\n",
    "is_issue = pd.read_csv(\"data/output/is_issue.csv\", index_col=\"stud_ID\")\n",
    "quality_score = pd.read_csv(\"data/output/quality_scores.csv\", index_col=\"stud_ID\")\n",
    "imputed_values = pd.read_csv(\"data/output/imputed_values.csv\", index_col=\"stud_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>letter_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stud_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f48f73</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0bd4e7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1795d</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  exam_1  exam_2  exam_3  notes  letter_grade\n",
       "stud_ID                                                    \n",
       "f48f73   False   False   False   False  False         False\n",
       "0bd4e7   False   False   False   False   True         False\n",
       "e1795d   False   False   False   False  False         False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_issue.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>letter_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stud_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f48f73</th>\n",
       "      <td>1</td>\n",
       "      <td>0.936789</td>\n",
       "      <td>0.924476</td>\n",
       "      <td>0.854220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0bd4e7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.900119</td>\n",
       "      <td>0.860793</td>\n",
       "      <td>0.876085</td>\n",
       "      <td>0.139237</td>\n",
       "      <td>0.771159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1795d</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897646</td>\n",
       "      <td>0.893876</td>\n",
       "      <td>0.704493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name    exam_1    exam_2    exam_3     notes  letter_grade\n",
       "stud_ID                                                            \n",
       "f48f73      1  0.936789  0.924476  0.854220  1.000000      0.811594\n",
       "0bd4e7      1  0.900119  0.860793  0.876085  0.139237      0.771159\n",
       "e1795d      1  0.897646  0.893876  0.704493  1.000000      0.490956"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_score.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function that will help us easily inspect the results for each column. The `inspect_column` function will take in the name of the column that you want to check for errors, and return a DataFrame that includes the original dataset alongside the three new columns for that column: `is_issue`, `quality_score`, and `imputed_value` which have been extracted from the CSV files returned by Data Inspector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_column(column_name):\n",
    "    is_issue_col = is_issue[column_name].rename(f\"{column_name}_is_issue\")\n",
    "    quality_score_col = quality_score[column_name].rename(f\"{column_name}_quality_score\")\n",
    "    imputed_values_col = imputed_values[column_name].rename(f\"{column_name}_imputed_value\")\n",
    "\n",
    "    merged_df = pd.concat([original_dataset, is_issue_col, quality_score_col, imputed_values_col], axis=1)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will take a closer look at the `letter_grade` column. Here we obtain the concatenated DataFrame using the function defined above, then filter for the examples where `is_issue` is `True` and sort the values by `quality_score` to view the top errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>letter_grade</th>\n",
       "      <th>letter_grade_is_issue</th>\n",
       "      <th>letter_grade_quality_score</th>\n",
       "      <th>letter_grade_imputed_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stud_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0bdad5</th>\n",
       "      <td>Courtney Richardson</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88e562</th>\n",
       "      <td>Ana Wells</td>\n",
       "      <td>98</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676b</th>\n",
       "      <td>Marion Wilkerson</td>\n",
       "      <td>81</td>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5eef2c</th>\n",
       "      <td>Andy Woods</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803b9</th>\n",
       "      <td>Patrick Stewart</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  exam_1  exam_2  exam_3  \\\n",
       "stud_ID                                                \n",
       "0bdad5   Courtney Richardson      62       0      42   \n",
       "88e562             Ana Wells      98      80      89   \n",
       "74676b      Marion Wilkerson      81     100      74   \n",
       "5eef2c            Andy Woods      90      78      81   \n",
       "1803b9       Patrick Stewart      75       0      55   \n",
       "\n",
       "                                notes letter_grade  letter_grade_is_issue  \\\n",
       "stud_ID                                                                     \n",
       "0bdad5     cheated on exam, gets 0pts            B                   True   \n",
       "88e562   great final presentation +10            C                   True   \n",
       "74676b                            NaN            F                   True   \n",
       "5eef2c                            NaN            A                   True   \n",
       "1803b9     cheated on exam, gets 0pts            A                   True   \n",
       "\n",
       "         letter_grade_quality_score letter_grade_imputed_value  \n",
       "stud_ID                                                         \n",
       "0bdad5                     0.000003                          F  \n",
       "88e562                     0.002002                          A  \n",
       "74676b                     0.006147                          B  \n",
       "5eef2c                     0.008590                          B  \n",
       "1803b9                     0.009317                          F  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_grade_df = inspect_column(\"letter_grade\")\n",
    "letter_grade_issues = letter_grade_df[letter_grade_df[\"letter_grade_is_issue\"] == True].sort_values(\"letter_grade_quality_score\")\n",
    "letter_grade_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grades for these students do look extremely suspicious. The `imputed_value` columns provides suggested values for the datapoint that has been indentified as an error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view another example of potential data issues. Let's check out the `exam_1` column and similarly view the top errors in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>letter_grade</th>\n",
       "      <th>exam_1_is_issue</th>\n",
       "      <th>exam_1_quality_score</th>\n",
       "      <th>exam_1_imputed_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stud_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2caa08</th>\n",
       "      <td>Nicholas Richardson</td>\n",
       "      <td>980</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>great participation +10</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>4.071307e-11</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d30e8a</th>\n",
       "      <td>Matthew Fleming</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>&lt;p&gt;&lt;samp&gt;Invalid entry.&lt;/p&gt;</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>1.073906e-01</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4d929</th>\n",
       "      <td>Timothy Turner</td>\n",
       "      <td>172</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>1.155312e-01</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86bd1a</th>\n",
       "      <td>Bernadette Larson</td>\n",
       "      <td>-20</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "      <td>1.692855e-01</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1dffd</th>\n",
       "      <td>Roosevelt Francis</td>\n",
       "      <td>69</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>great participation +10</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>2.287622e-01</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  exam_1  exam_2  exam_3  \\\n",
       "stud_ID                                                \n",
       "2caa08   Nicholas Richardson     980      94      90   \n",
       "d30e8a       Matthew Fleming       0      89      91   \n",
       "b4d929        Timothy Turner     172      70      68   \n",
       "86bd1a     Bernadette Larson     -20      38      29   \n",
       "e1dffd     Roosevelt Francis      69      94      95   \n",
       "\n",
       "                               notes letter_grade  exam_1_is_issue  \\\n",
       "stud_ID                                                              \n",
       "2caa08       great participation +10            A             True   \n",
       "d30e8a   <p><samp>Invalid entry.</p>            A             True   \n",
       "b4d929                           NaN            C             True   \n",
       "86bd1a                           NaN            F             True   \n",
       "e1dffd       great participation +10            A             True   \n",
       "\n",
       "         exam_1_quality_score  exam_1_imputed_value  \n",
       "stud_ID                                              \n",
       "2caa08           4.071307e-11                    89  \n",
       "d30e8a           1.073906e-01                    83  \n",
       "b4d929           1.155312e-01                    91  \n",
       "86bd1a           1.692855e-01                    46  \n",
       "e1dffd           2.287622e-01                   123  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_1_df = inspect_column(\"exam_1\")\n",
    "exam_1_issues = exam_1_df[exam_1_df[\"exam_1_is_issue\"] == True].sort_values(\"exam_1_quality_score\")\n",
    "exam_1_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we see that these exam scores are likely erroneous. By easily repeating this with each column in your dataset, this is a straightforward method to inspect your data for any potential errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to ensure that you have high quality data is to manually inspect the datapoints that Data Inspector has identified to have issues (ie. `is_issue = True`) and correct them. However, that could be very time consuming and hence you can also quickly improve your data by replacing the entries that have been flaged as issues with the suggested imputed values.\n",
    "\n",
    "We demonstrate how to automatically obtain an improved dataset below, where `improved_dataset` will have the exact same rows and columns as your original dataset, but with the erroneous rows replaced with a suggested value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>letter_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stud_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f48f73</th>\n",
       "      <td>Nicole Carter</td>\n",
       "      <td>53</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0bd4e7</th>\n",
       "      <td>Tammy Myers</td>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1795d</th>\n",
       "      <td>Lillian Lucas</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb9d7a</th>\n",
       "      <td>Danielle Graham</td>\n",
       "      <td>61</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9acca4</th>\n",
       "      <td>Wilbur Fleming</td>\n",
       "      <td>48</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  exam_1  exam_2  exam_3  \\\n",
       "stud_ID                                            \n",
       "f48f73     Nicole Carter      53      77      93   \n",
       "0bd4e7       Tammy Myers      81      64      80   \n",
       "e1795d     Lillian Lucas      74      88      97   \n",
       "cb9d7a   Danielle Graham      61      94      78   \n",
       "9acca4    Wilbur Fleming      48      90      91   \n",
       "\n",
       "                                notes letter_grade  \n",
       "stud_ID                                             \n",
       "f48f73                            NaN            C  \n",
       "0bd4e7   great final presentation +10            B  \n",
       "e1795d                            NaN            B  \n",
       "cb9d7a                            NaN            C  \n",
       "9acca4                            NaN            C  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_dataset = original_dataset.copy()\n",
    "\n",
    "for col in is_issue.columns:\n",
    "    improved_dataset[col].mask(is_issue[col], imputed_values[col], inplace=True)\n",
    "    \n",
    "improved_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note about Real-time and Batch Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, real-time and batch inference has no effect for the Data Inspector, do not try using it. All results are returned at the end of the training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Resources (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below contains the code that can be used to automatically delete the files created in S3 in this sample notebook. Be wary that this command will delete all the files stored in the `base_folder_name` folder specified above. **Proceed with caution** if you have previously stored other files in that folder.\n",
    "\n",
    "Alternatively, you can navigate to the [S3 Management Console](https://s3.console.aws.amazon.com/) and manually delete these data files yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resource = session.resource('s3')\n",
    "# resource_bucket = resource.Bucket(bucket_name)\n",
    "\n",
    "# # before executing the code below, ensure there is nothing else important in this folder\n",
    "# resource_bucket.objects.filter(Prefix=f\"{base_folder_name}/\").delete()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Additional Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ask questions or report problems, please email: support@cleanlab.ai and specify that you are using Data Inspector in AWS Marketplace in the subject line.\n",
    "\n",
    "To run a more in-depth analysis of your data and labels, try [Cleanlab Studio](https://cleanlab.ai/studio/) for free (it supports image data as well)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
